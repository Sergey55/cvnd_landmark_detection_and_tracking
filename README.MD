# Landmark Detection & Tracking

## Project Overview

In this project I have implemented SLAM (Simultanious Localization and Mapping) for a 2 dimensional world. The basis for simultaneous localization and mapping (SLAM) is to gather information from a robot's sensors and motions over time, and then use information about measurements and motion to re-construct a map of the world. 

## Files

* 1. Robot Moving and Sensing.html - Export of `1. Robot Moving and Sensing.ipynb` notebook to HTML
* 1. Robot Moving and Sensing.ipynb - Overview of `robot` class and world visualisation
* 2. Omega and Xi, Constraints.ipynb - Omega and Xi
* 3. Landmark Detection and Tracking.html - Export of `3. Landmark Detection and Tracking.ipynb` notebook to HTML
* 3. Landmark Detection and Tracking.ipynb - SLAM implementation and visualisation
* env.yml - Conda env description
* pkgs.txt - Pakcage list
* robot_class.py - Implementation of Robot class

## Results

Using SLAM algorithms and information about measurements and motions virtual 2D world was reconstructed and the last robots' location was detected. 
